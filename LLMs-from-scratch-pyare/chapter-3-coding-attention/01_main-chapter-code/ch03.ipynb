{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f22086",
   "metadata": {},
   "source": [
    "# Chapter 03 : Coding Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70dcdb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\" torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9ed3a",
   "metadata": {},
   "source": [
    "\n",
    "Workflow till now\n",
    "\n",
    "<div align = \"center\">\n",
    "    <img src = \"/DATA/pyare/Routine/LLM/Reasoning/LLMs-from-scratch-pyare/chapter-3-coding-attention/Ref_images/3.0.png\" center width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9073dde",
   "metadata": {},
   "source": [
    "- In this chapter we will code \n",
    "\n",
    "<img src=\"/DATA/pyare/Routine/LLM/Reasoning/LLMs-from-scratch-pyare/chapter-3-coding-attention/Ref_images/3.2.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365de207",
   "metadata": {},
   "source": [
    "### 3.3.1 A Simple self-attention mechanism without trainable weights\n",
    "<img src =\"/DATA/pyare/Routine/LLM/Reasoning/LLMs-from-scratch-pyare/chapter-3-coding-attention/Ref_images/3.7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a43f10",
   "metadata": {},
   "source": [
    "- Input sequence $x$, consisting of $T$ elements represented as $x^{(1)}$ to $x^{(T)}$\n",
    "\n",
    "Example: \"Your journey starts with one step\"\n",
    "- $x^{(1)}$, corresponds to a d-dimentional embedding vector representing a specific token, like \"Your\" has 3 dimentional embeddings.\n",
    "\n",
    "In **self-attention** your goal is to calculate context vectors $z^{(i)}$ for each element in the input sequence.\n",
    "\n",
    "- A ***Context Vector*** can be interpreted as an enriched embedding vector.\n",
    "\n",
    "- We will illustrate this with taking the word \"journey\" $x^{(2)}$ and the corresponding context vector $z^{(2)}$ which contains the infrmation about $x^{(2)}$ and all other input elements, $x^{(1)}$ to $x^{(T)}$.\n",
    "\n",
    "- First we will do simplified attention and later we will add trainable weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2) # query\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1448ff",
   "metadata": {},
   "source": [
    "- First step of implementing self-attention is to comppute the intermediate values *w*, referred as ***attention scores***.\n",
    "\n",
    "<img src=\"/DATA/pyare/Routine/LLM/Reasoning/LLMs-from-scratch-pyare/chapter-3-coding-attention/Ref_images/3.8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf204ff9",
   "metadata": {},
   "source": [
    "### Attention Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7d6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] #  journey  (x^2)\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0]) # \n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111e39d",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
    "        x^1     x^2     x^3     x^4     x^5     x^6\n",
    "        Your   journey starts   with    one    step\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02a75f",
   "metadata": {},
   "source": [
    "### Understanding the dot product (bilinear - 2 vectors)\n",
    "An dot product is essentially a concise way of multiplying two vectors element wise and then summing the products. Which is demonstrated as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f94efbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4300, 0.1500, 0.8900])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0] # Yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6556206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standard Attention (dot product of 2 vectors) ===\n",
      "tensor(0.9544)\n",
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "### Understanding the dot product (bilinear - 2 vectors)\n",
    "print(\"=== Standard Attention (dot product of 2 vectors) ===\")\n",
    "res = 0\n",
    "for idx, element in enumerate(inputs[0]):\n",
    "    res += inputs[0][idx]*query[idx] # element wise multiplication and addition\n",
    "print(res)\n",
    "print(torch.dot(inputs[0],query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c1eb2",
   "metadata": {},
   "source": [
    "#### 2-simplicial Attention scores: 2D scores (for single query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4ebe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2-Simplicial attention scores: \n",
      "tensor([[0.6441, 0.6313, 0.6217, 0.3216, 0.2735, 0.4393],\n",
      "        [0.6313, 1.1124, 1.0946, 0.6493, 0.4657, 0.8602],\n",
      "        [0.6217, 1.0946, 1.0776, 0.6373, 0.4685, 0.8396],\n",
      "        [0.3216, 0.6493, 0.6373, 0.3912, 0.2411, 0.5295],\n",
      "        [0.2735, 0.4657, 0.4685, 0.2411, 0.3871, 0.2315],\n",
      "        [0.4393, 0.8602, 0.8396, 0.5295, 0.2315, 0.7578]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2s = torch.empty(inputs.shape[0],inputs.shape[0]) # 6*6 = number of tokes * number of tokens\n",
    "for j, k_j in enumerate(inputs):\n",
    "    for k, k_prime_k in enumerate(inputs):\n",
    "        attn_scores_2s[j,k] = torch.sum(query* k_j* k_prime_k)\n",
    "\n",
    "print(\"\\n2-Simplicial attention scores: \")\n",
    "print(attn_scores_2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3790c",
   "metadata": {},
   "source": [
    "```\n",
    "                k=0     k=1     k=2     k=3     k=4     k=5\n",
    "                Your   journey starts   with    one    step\n",
    "            ┌──────────────────────────────────────────────  ┐\n",
    "j=0  Your   │ 0.6441  0.6313  0.6217  0.3216  0.2735  0.4393 │\n",
    "j=1 journey │ 0.6313  1.1124  1.0946  0.6493  0.4657  0.8602 │\n",
    "j=2 starts  │ 0.6217  1.0946  1.0776  0.6373  0.4685  0.8396 │\n",
    "j=3  with   │ 0.3216  0.6493  0.6373  0.3912  0.2411  0.5295 │\n",
    "j=4  one    │ 0.2735  0.4657  0.4685  0.2411  0.3871  0.2315 │\n",
    "j=5  step   │ 0.4393  0.8602  0.8396  0.5295  0.2315  0.7578 │\n",
    "            └──────────────────────────────────────────────  ┘\n",
    "```\n",
    "\n",
    "**Interpretation:** 36 scores (6×6) representing how much query (journey) attends to each pair of tokens.\n",
    "\n",
    "- [0,0] = 0.6441 (Your, Your)journey attending to \"Your\" paired with \"Your\"\n",
    "- [0,2] = 0.6217(Your, starts)journey attending to \"Your\" paired with \"starts\"\n",
    "- [1,2] = 1.0946(journey, starts)journey attending to \"journey\" paired with \"starts\"\n",
    "- [4,5] = 0.2315(one, step)journey attending to \"one\" paired with \"step\"\n",
    "\n",
    "```\n",
    "Standard:     query → token           (6 pairs)\n",
    "              journey → Your, journey → starts, ...\n",
    "\n",
    "2-Simplicial: query → (token, token)  (36 triplets)\n",
    "              journey → (Your, Your), journey → (Your, journey), journey → (Your, starts), ...\n",
    "\n",
    "```\n",
    "\n",
    "So instead of 6 attention scores, we have 36 attention scores - one for every possible pair of tokens that the query can attend to together!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e982e",
   "metadata": {},
   "source": [
    "#### Understanding the trilinear product (3 vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d458b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2-Simplicial Attention (trilinear product of 3 vectors) ===\n",
      "tensor(0.6217)\n",
      "tensor(0.6217)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 2-Simplicial Attention (trilinear product of 3 vectors) ===\")\n",
    "# For A[query, j=0, k=2] = trilinear(query, inputs[0], inputs[2])\n",
    "j = 0  # Your\n",
    "k = 2  # starts\n",
    "\n",
    "res = 0\n",
    "for idx in range(len(query)):\n",
    "    res += query[idx]* inputs[j][idx] * inputs[k][idx] # # element wise multiplication of 3 vectors and addition\n",
    "\n",
    "print(res)\n",
    "print(torch.sum(query * inputs[j] * inputs[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84260b1e",
   "metadata": {},
   "source": [
    "## Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c76eab",
   "metadata": {},
   "source": [
    "- We normalize each attention scores  we computed previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2755d78",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
