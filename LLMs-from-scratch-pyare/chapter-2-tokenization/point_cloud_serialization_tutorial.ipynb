{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Serialization Tutorial (PTv3/LitePT)\n",
    "\n",
    "This notebook walks through the **serialization process** used in Point Transformer V3 (PTv3) and LitePT.\n",
    "\n",
    "We'll use your car point cloud to understand:\n",
    "1. **Grid Quantization** - Converting continuous coordinates to discrete grid\n",
    "2. **Z-Order (Morton) Encoding** - Converting 3D coords to 1D codes\n",
    "3. **Sorting & Serialization** - Creating ordered sequences\n",
    "4. **Patch Grouping** - Grouping points for local attention\n",
    "5. **Shuffle Order Strategy** - Using multiple serialization patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# For nice inline plots\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Point Cloud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your CSV path\n",
    "CSV_PATH = \"/DATA/pyare/Routine/LLM/Reasoning/LLMs-from-scratch-pyare/chapter-2-tokenization/car_pcloud.csv\"\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(f\"Loaded {len(df)} points\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates\n",
    "coords_raw = df[['x', 'y', 'z']].values\n",
    "\n",
    "print(\"Raw coordinate ranges:\")\n",
    "print(f\"  X: [{coords_raw[:, 0].min():.2f}, {coords_raw[:, 0].max():.2f}]\")\n",
    "print(f\"  Y: [{coords_raw[:, 1].min():.2f}, {coords_raw[:, 1].max():.2f}]\")\n",
    "print(f\"  Z: [{coords_raw[:, 2].min():.2f}, {coords_raw[:, 2].max():.2f}]\")\n",
    "\n",
    "# Normalize to start from origin (0, 0, 0)\n",
    "coords = coords_raw - coords_raw.min(axis=0)\n",
    "\n",
    "print(f\"\\nNormalized coordinate ranges:\")\n",
    "print(f\"  X: [{coords[:, 0].min():.2f}, {coords[:, 0].max():.2f}]\")\n",
    "print(f\"  Y: [{coords[:, 1].min():.2f}, {coords[:, 1].max():.2f}]\")\n",
    "print(f\"  Z: [{coords[:, 2].min():.2f}, {coords[:, 2].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original point cloud\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Colored by intensity\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "scatter1 = ax1.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "                       c=df['intensity'].values, cmap='viridis', s=1)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('Car Point Cloud (colored by intensity)')\n",
    "plt.colorbar(scatter1, ax=ax1, shrink=0.5, label='Intensity')\n",
    "\n",
    "# Colored by Z (height)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "scatter2 = ax2.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "                       c=coords[:, 2], cmap='jet', s=1)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "ax2.set_title('Car Point Cloud (colored by height)')\n",
    "plt.colorbar(scatter2, ax=ax2, shrink=0.5, label='Z height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal points: {len(coords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Grid Quantization\n",
    "\n",
    "**Purpose:** Convert continuous 3D coordinates into discrete grid coordinates.\n",
    "\n",
    "This is essential because:\n",
    "1. Morton/Hilbert codes work on integers\n",
    "2. It acts as a form of voxelization\n",
    "3. Controls the resolution of the serialization\n",
    "\n",
    "```\n",
    "Continuous (0.15, 0.27, 0.43) → Grid (1, 2, 4) with grid_size=0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_to_grid(coords: np.ndarray, grid_size: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert continuous 3D coordinates to discrete grid coordinates.\n",
    "    \n",
    "    Args:\n",
    "        coords: (N, 3) array of [x, y, z] coordinates\n",
    "        grid_size: Size of each voxel (e.g., 0.1 = 10cm)\n",
    "    \n",
    "    Returns:\n",
    "        grid_coords: (N, 3) array of integer grid coordinates\n",
    "    \"\"\"\n",
    "    grid_coords = np.floor(coords / grid_size).astype(np.int64)\n",
    "    return grid_coords\n",
    "\n",
    "# Choose grid size (experiment with different values!)\n",
    "GRID_SIZE = 0.05  # 5cm voxels\n",
    "\n",
    "grid_coords = quantize_to_grid(coords, GRID_SIZE)\n",
    "\n",
    "print(f\"Grid size: {GRID_SIZE}m ({GRID_SIZE*100}cm)\")\n",
    "print(f\"\\nGrid coordinate ranges:\")\n",
    "print(f\"  X: [{grid_coords[:, 0].min()}, {grid_coords[:, 0].max()}] ({grid_coords[:, 0].max() - grid_coords[:, 0].min() + 1} cells)\")\n",
    "print(f\"  Y: [{grid_coords[:, 1].min()}, {grid_coords[:, 1].max()}] ({grid_coords[:, 1].max() - grid_coords[:, 1].min() + 1} cells)\")\n",
    "print(f\"  Z: [{grid_coords[:, 2].min()}, {grid_coords[:, 2].max()}] ({grid_coords[:, 2].max() - grid_coords[:, 2].min() + 1} cells)\")\n",
    "\n",
    "# Count unique grid cells\n",
    "unique_cells = len(np.unique(grid_coords, axis=0))\n",
    "print(f\"\\nUnique grid cells: {unique_cells} (out of {len(coords)} points)\")\n",
    "print(f\"Average points per cell: {len(coords) / unique_cells:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few example points\n",
    "print(\"Example: Continuous → Grid conversion\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Point':<8} {'Continuous (x,y,z)':<30} {'Grid (gx,gy,gz)':<20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in [0, 1, 2, 100, 500, len(coords)-1]:\n",
    "    cx, cy, cz = coords[i]\n",
    "    gx, gy, gz = grid_coords[i]\n",
    "    print(f\"P{i:<6} ({cx:>7.3f}, {cy:>7.3f}, {cz:>7.3f})    ({gx:>3}, {gy:>3}, {gz:>3})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Z-Order (Morton) Encoding\n",
    "\n",
    "**Purpose:** Convert 3D grid coordinates into a single 1D integer code.\n",
    "\n",
    "**How it works:** Interleave the bits of x, y, z coordinates.\n",
    "\n",
    "```\n",
    "Example: Point at grid (5, 3, 2)\n",
    "  x = 5 = 101 (binary)\n",
    "  y = 3 = 011 (binary)\n",
    "  z = 2 = 010 (binary)\n",
    "  \n",
    "Interleave (z₂y₂x₂ z₁y₁x₁ z₀y₀x₀):\n",
    "  bit 2: z=0, y=0, x=1 → 001\n",
    "  bit 1: z=1, y=1, x=0 → 110\n",
    "  bit 0: z=0, y=1, x=1 → 011\n",
    "  \n",
    "Result: 001 110 011 = 118 (decimal)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_order_encode(grid_coords: np.ndarray, depth: int = 16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encode 3D grid coordinates into Z-order (Morton) codes.\n",
    "    \n",
    "    Args:\n",
    "        grid_coords: (N, 3) array of integer grid coordinates\n",
    "        depth: Number of bits per dimension (max coord = 2^depth - 1)\n",
    "    \n",
    "    Returns:\n",
    "        codes: (N,) array of Morton codes\n",
    "    \"\"\"\n",
    "    x = grid_coords[:, 0].astype(np.uint64)\n",
    "    y = grid_coords[:, 1].astype(np.uint64)\n",
    "    z = grid_coords[:, 2].astype(np.uint64)\n",
    "    \n",
    "    codes = np.zeros(len(x), dtype=np.uint64)\n",
    "    \n",
    "    # Interleave bits: for each bit position, place x, y, z bits\n",
    "    for i in range(depth):\n",
    "        x_bit = (x >> i) & 1\n",
    "        y_bit = (y >> i) & 1\n",
    "        z_bit = (z >> i) & 1\n",
    "        \n",
    "        # Place in interleaved positions\n",
    "        codes |= (x_bit << (3 * i))      # x at position 3i\n",
    "        codes |= (y_bit << (3 * i + 1))  # y at position 3i+1\n",
    "        codes |= (z_bit << (3 * i + 2))  # z at position 3i+2\n",
    "    \n",
    "    return codes\n",
    "\n",
    "# Compute Morton codes\n",
    "morton_codes = z_order_encode(grid_coords)\n",
    "\n",
    "print(f\"Morton codes computed for {len(morton_codes)} points\")\n",
    "print(f\"Code range: [{morton_codes.min()}, {morton_codes.max()}]\")\n",
    "print(f\"Unique codes: {len(np.unique(morton_codes))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's trace through a few examples step by step\n",
    "def explain_morton_encoding(gx: int, gy: int, gz: int, depth: int = 8) -> int:\n",
    "    \"\"\"\n",
    "    Explain Morton encoding step by step.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEncoding point ({gx}, {gy}, {gz}):\")\n",
    "    print(f\"  x = {gx} = {bin(gx)} (binary)\")\n",
    "    print(f\"  y = {gy} = {bin(gy)} (binary)\")\n",
    "    print(f\"  z = {gz} = {bin(gz)} (binary)\")\n",
    "    \n",
    "    code = 0\n",
    "    interleaved_bits = \"\"\n",
    "    \n",
    "    print(f\"\\n  Bit interleaving (z_i, y_i, x_i for each position i):\")\n",
    "    \n",
    "    for i in range(depth):\n",
    "        x_bit = (gx >> i) & 1\n",
    "        y_bit = (gy >> i) & 1\n",
    "        z_bit = (gz >> i) & 1\n",
    "        \n",
    "        code |= (x_bit << (3 * i))\n",
    "        code |= (y_bit << (3 * i + 1))\n",
    "        code |= (z_bit << (3 * i + 2))\n",
    "        \n",
    "        interleaved_bits = f\"{z_bit}{y_bit}{x_bit}\" + interleaved_bits\n",
    "        \n",
    "        if i < 4:  # Show first 4 bits\n",
    "            print(f\"    bit {i}: z={z_bit}, y={y_bit}, x={x_bit} → {z_bit}{y_bit}{x_bit}\")\n",
    "    \n",
    "    print(f\"\\n  Interleaved: {interleaved_bits}\")\n",
    "    print(f\"  Morton code: {code}\")\n",
    "    \n",
    "    return code\n",
    "\n",
    "# Examples from your data\n",
    "print(\"=\" * 60)\n",
    "print(\"MORTON ENCODING EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in [0, 10, 100]:\n",
    "    gx, gy, gz = grid_coords[i]\n",
    "    explain_morton_encoding(gx, gy, gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Sorting (Serialization)\n",
    "\n",
    "**Purpose:** Sort points by their Morton codes to create an ordered sequence.\n",
    "\n",
    "After sorting:\n",
    "- Points with low Morton codes come first\n",
    "- Spatially nearby points tend to be close in the sequence\n",
    "- This is the \"serialization\" - converting unordered 3D points to ordered 1D sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Morton codes\n",
    "sorted_indices = np.argsort(morton_codes)\n",
    "inverse_indices = np.argsort(sorted_indices)  # To restore original order\n",
    "\n",
    "print(\"Serialization complete!\")\n",
    "print(f\"\\nFirst 10 points in serialized order:\")\n",
    "print(f\"{'Rank':<6} {'Orig Idx':<10} {'Grid (x,y,z)':<20} {'Morton Code':<15} {'Continuous (x,y,z)'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank in range(10):\n",
    "    orig_idx = sorted_indices[rank]\n",
    "    gx, gy, gz = grid_coords[orig_idx]\n",
    "    cx, cy, cz = coords[orig_idx]\n",
    "    code = morton_codes[orig_idx]\n",
    "    print(f\"{rank:<6} {orig_idx:<10} ({gx:>3},{gy:>3},{gz:>3}){'':>8} {code:<15} ({cx:.2f}, {cy:.2f}, {cz:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the serialization order\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Create colors based on serialization position\n",
    "serial_position = np.zeros(len(coords))\n",
    "for i, idx in enumerate(sorted_indices):\n",
    "    serial_position[idx] = i\n",
    "\n",
    "# Original order\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "           c=np.arange(len(coords)), cmap='viridis', s=1)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('Original Order\\n(colored by original index)')\n",
    "\n",
    "# Serialized order (colored by position in serialized sequence)\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "scatter = ax2.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "                      c=serial_position, cmap='viridis', s=1)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "ax2.set_title('Z-Order Serialization\\n(colored by serial position)')\n",
    "plt.colorbar(scatter, ax=ax2, shrink=0.5, label='Serial Position')\n",
    "\n",
    "# Show just the first N points in serialized order\n",
    "N_SHOW = 200\n",
    "first_n_indices = sorted_indices[:N_SHOW]\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(coords[first_n_indices, 0], \n",
    "           coords[first_n_indices, 1], \n",
    "           coords[first_n_indices, 2], \n",
    "           c=np.arange(N_SHOW), cmap='plasma', s=5)\n",
    "ax3.set_xlabel('X')\n",
    "ax3.set_ylabel('Y')\n",
    "ax3.set_zlabel('Z')\n",
    "ax3.set_title(f'First {N_SHOW} points in Z-order\\n(spatially clustered!)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNotice: The first {N_SHOW} points in Z-order are spatially clustered!\")\n",
    "print(\"This is the locality-preserving property of Morton codes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Trans Z-Order (Swap X and Y)\n",
    "\n",
    "**Purpose:** Create a different serialization pattern by swapping axes.\n",
    "\n",
    "PTv3 uses **4 different patterns** and cycles through them:\n",
    "1. Z-order (x, y, z)\n",
    "2. Trans Z-order (y, x, z) ← swap x and y\n",
    "3. Hilbert\n",
    "4. Trans Hilbert\n",
    "\n",
    "This ensures different points are grouped together in different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_order_encode_trans(grid_coords: np.ndarray, depth: int = 16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Trans Z-order: Swap x and y axes before encoding.\n",
    "    \"\"\"\n",
    "    # Swap x and y columns\n",
    "    transposed = grid_coords[:, [1, 0, 2]]  # [y, x, z] instead of [x, y, z]\n",
    "    return z_order_encode(transposed, depth)\n",
    "\n",
    "# Compute Trans Z-order codes\n",
    "morton_codes_trans = z_order_encode_trans(grid_coords)\n",
    "sorted_indices_trans = np.argsort(morton_codes_trans)\n",
    "\n",
    "print(\"Comparing Z-order vs Trans Z-order:\")\n",
    "print(\"\\nFirst 10 points in each order:\")\n",
    "print(f\"{'Rank':<6} {'Z-order Idx':<12} {'Trans Z-order Idx':<18} {'Same?'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for rank in range(10):\n",
    "    z_idx = sorted_indices[rank]\n",
    "    zt_idx = sorted_indices_trans[rank]\n",
    "    same = \"✓\" if z_idx == zt_idx else \"✗\"\n",
    "    print(f\"{rank:<6} {z_idx:<12} {zt_idx:<18} {same}\")\n",
    "\n",
    "# Count how many are in different positions\n",
    "different = np.sum(sorted_indices != sorted_indices_trans)\n",
    "print(f\"\\nPoints in different positions: {different} / {len(sorted_indices)} ({100*different/len(sorted_indices):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize both serializations\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "N_SHOW = 300\n",
    "\n",
    "# Z-order first N points\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "first_z = sorted_indices[:N_SHOW]\n",
    "ax1.scatter(coords[first_z, 0], coords[first_z, 1], coords[first_z, 2], \n",
    "           c=np.arange(N_SHOW), cmap='plasma', s=3)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title(f'Z-Order: First {N_SHOW} points')\n",
    "\n",
    "# Trans Z-order first N points\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "first_zt = sorted_indices_trans[:N_SHOW]\n",
    "ax2.scatter(coords[first_zt, 0], coords[first_zt, 1], coords[first_zt, 2], \n",
    "           c=np.arange(N_SHOW), cmap='plasma', s=3)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "ax2.set_title(f'Trans Z-Order: First {N_SHOW} points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: The spatial clustering pattern is different!\")\n",
    "print(\"This is why PTv3 uses multiple serialization patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Patch Grouping\n",
    "\n",
    "**Purpose:** Split the serialized sequence into fixed-size patches.\n",
    "\n",
    "**Why?** \n",
    "- Global attention has O(N²) complexity - too expensive!\n",
    "- Local attention within patches: O(K²) per patch, O(N/K × K²) = O(NK) total\n",
    "- With K=64 and N=2000: speedup from 4M to 128K operations!\n",
    "\n",
    "```\n",
    "Serialized: [P₁, P₂, P₃, P₄, P₅, P₆, P₇, P₈, P₉, P₁₀, ...]\n",
    "             └─────────────┘  └─────────────┘\n",
    "                 Patch 0          Patch 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_into_patches(\n",
    "    n_points: int,\n",
    "    sorted_indices: np.ndarray,\n",
    "    patch_size: int = 64\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Group serialized points into non-overlapping patches.\n",
    "    \n",
    "    Args:\n",
    "        n_points: Total number of points\n",
    "        sorted_indices: Serialization order\n",
    "        patch_size: Number of points per patch (K in PTv3, typically 1024)\n",
    "    \n",
    "    Returns:\n",
    "        patches: List of index arrays, one per patch\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    \n",
    "    for i in range(0, n_points, patch_size):\n",
    "        end_idx = min(i + patch_size, n_points)\n",
    "        patch_indices = sorted_indices[i:end_idx].copy()\n",
    "        \n",
    "        # Pad last patch if necessary (borrow from previous points)\n",
    "        if len(patch_indices) < patch_size and i > 0:\n",
    "            pad_size = patch_size - len(patch_indices)\n",
    "            padding = sorted_indices[i - pad_size:i]\n",
    "            patch_indices = np.concatenate([patch_indices, padding])\n",
    "        \n",
    "        patches.append(patch_indices)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "# Create patches\n",
    "PATCH_SIZE = 64  # PTv3 uses 1024, we use smaller for visualization\n",
    "\n",
    "patches = group_into_patches(len(coords), sorted_indices, PATCH_SIZE)\n",
    "\n",
    "print(f\"Patch size: {PATCH_SIZE}\")\n",
    "print(f\"Number of patches: {len(patches)}\")\n",
    "print(f\"\\nPatch details:\")\n",
    "print(f\"{'Patch':<8} {'Size':<8} {'First Idx':<12} {'Last Idx':<12} {'Spatial Extent (Δx, Δy, Δz)'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, patch in enumerate(patches[:10]):  # Show first 10 patches\n",
    "    patch_coords = coords[patch]\n",
    "    dx = patch_coords[:, 0].max() - patch_coords[:, 0].min()\n",
    "    dy = patch_coords[:, 1].max() - patch_coords[:, 1].min()\n",
    "    dz = patch_coords[:, 2].max() - patch_coords[:, 2].min()\n",
    "    print(f\"{i:<8} {len(patch):<8} {patch[0]:<12} {patch[-1]:<12} ({dx:.2f}, {dy:.2f}, {dz:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize patches\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "# View 1: All patches with different colors\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "\n",
    "for i, patch in enumerate(patches):\n",
    "    patch_coords = coords[patch]\n",
    "    ax1.scatter(patch_coords[:, 0], patch_coords[:, 1], patch_coords[:, 2],\n",
    "               c=[colors[i % 20]], s=2, alpha=0.7, \n",
    "               label=f'Patch {i}' if i < 5 else None)\n",
    "\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title(f'All {len(patches)} Patches\\n(20 colors cycling)')\n",
    "ax1.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "# View 2: First 5 patches only\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "distinct_colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "for i, patch in enumerate(patches[:5]):\n",
    "    patch_coords = coords[patch]\n",
    "    ax2.scatter(patch_coords[:, 0], patch_coords[:, 1], patch_coords[:, 2],\n",
    "               c=distinct_colors[i], s=10, alpha=0.8, label=f'Patch {i}')\n",
    "\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "ax2.set_title('First 5 Patches\\n(spatially localized!)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Each patch contains spatially nearby points!\")\n",
    "print(\"Attention within each patch captures local relationships.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Shuffle Order Strategy\n",
    "\n",
    "**Problem:** With fixed patches, points in Patch 0 never attend to points in Patch 5.\n",
    "\n",
    "**Solution:** Use different serialization patterns in different attention layers!\n",
    "\n",
    "```\n",
    "Layer 0: Z-order        → Patches: [A,B,C,D], [E,F,G,H], ...\n",
    "Layer 1: Trans Z-order  → Patches: [A,C,E,G], [B,D,F,H], ...  ← Different grouping!\n",
    "Layer 2: Hilbert        → Patches: [A,B,E,F], [C,D,G,H], ...  ← Another grouping!\n",
    "Layer 3: Trans Hilbert  → Patches: [A,D,E,H], [B,C,F,G], ...\n",
    "```\n",
    "\n",
    "Over multiple layers, every point eventually attends to every other point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hilbert_encode_simple(grid_coords: np.ndarray, depth: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simplified Hilbert-like encoding (not true Hilbert, but demonstrates variety).\n",
    "    \"\"\"\n",
    "    x = grid_coords[:, 0].astype(np.uint64)\n",
    "    y = grid_coords[:, 1].astype(np.uint64)\n",
    "    z = grid_coords[:, 2].astype(np.uint64)\n",
    "    \n",
    "    codes = np.zeros(len(x), dtype=np.uint64)\n",
    "    \n",
    "    for i in range(depth):\n",
    "        x_bit = (x >> i) & 1\n",
    "        y_bit = (y >> i) & 1\n",
    "        z_bit = (z >> i) & 1\n",
    "        \n",
    "        # Different interleaving pattern than Z-order\n",
    "        if i % 2 == 0:\n",
    "            codes |= (z_bit << (3 * i))\n",
    "            codes |= (x_bit << (3 * i + 1))\n",
    "            codes |= (y_bit << (3 * i + 2))\n",
    "        else:\n",
    "            codes |= (y_bit << (3 * i))\n",
    "            codes |= (z_bit << (3 * i + 1))\n",
    "            codes |= (x_bit << (3 * i + 2))\n",
    "    \n",
    "    return codes\n",
    "\n",
    "def serialize_all_patterns(grid_coords: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Compute all 4 serialization patterns used in PTv3.\n",
    "    \"\"\"\n",
    "    patterns = {}\n",
    "    \n",
    "    # Z-order\n",
    "    codes = z_order_encode(grid_coords)\n",
    "    patterns['z'] = np.argsort(codes)\n",
    "    \n",
    "    # Trans Z-order\n",
    "    codes = z_order_encode_trans(grid_coords)\n",
    "    patterns['z-trans'] = np.argsort(codes)\n",
    "    \n",
    "    # Hilbert (simplified)\n",
    "    codes = hilbert_encode_simple(grid_coords)\n",
    "    patterns['hilbert'] = np.argsort(codes)\n",
    "    \n",
    "    # Trans Hilbert\n",
    "    transposed = grid_coords[:, [1, 0, 2]]\n",
    "    codes = hilbert_encode_simple(transposed)\n",
    "    patterns['hilbert-trans'] = np.argsort(codes)\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Compute all patterns\n",
    "all_patterns = serialize_all_patterns(grid_coords)\n",
    "\n",
    "print(\"All 4 serialization patterns computed!\")\n",
    "print(\"\\nFirst 10 indices in each pattern:\")\n",
    "for name, indices in all_patterns.items():\n",
    "    print(f\"  {name:<15}: {indices[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how Patch 0 changes across patterns\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "pattern_names = list(all_patterns.keys())\n",
    "colors_patch = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for idx, (name, sorted_idx) in enumerate(all_patterns.items()):\n",
    "    ax = fig.add_subplot(1, 4, idx + 1, projection='3d')\n",
    "    \n",
    "    # Get first patch\n",
    "    patch_0 = sorted_idx[:PATCH_SIZE]\n",
    "    patch_0_coords = coords[patch_0]\n",
    "    \n",
    "    # Plot all points in gray\n",
    "    ax.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "              c='lightgray', s=1, alpha=0.3)\n",
    "    \n",
    "    # Highlight Patch 0\n",
    "    ax.scatter(patch_0_coords[:, 0], patch_0_coords[:, 1], patch_0_coords[:, 2],\n",
    "              c=colors_patch[idx], s=10, alpha=0.9)\n",
    "    \n",
    "    # Compute centroid\n",
    "    centroid = patch_0_coords.mean(axis=0)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(f'{name}\\nPatch 0 centroid: ({centroid[0]:.1f}, {centroid[1]:.1f}, {centroid[2]:.1f})')\n",
    "\n",
    "plt.suptitle('Shuffle Order: Patch 0 is DIFFERENT in each serialization pattern!', fontsize=12, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Different serialization patterns group different points together!\")\n",
    "print(\"This is why PTv3 cycles through patterns: [z → z-trans → hilbert → hilbert-trans → z → ...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze overlap between Patch 0 across different patterns\n",
    "print(\"Overlap analysis between Patch 0 across patterns:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pattern_names = list(all_patterns.keys())\n",
    "patch_0_sets = {name: set(indices[:PATCH_SIZE]) for name, indices in all_patterns.items()}\n",
    "\n",
    "print(f\"\\n{'Pattern 1':<15} {'Pattern 2':<15} {'Overlap':<10} {'Percentage'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, name1 in enumerate(pattern_names):\n",
    "    for name2 in pattern_names[i+1:]:\n",
    "        overlap = len(patch_0_sets[name1] & patch_0_sets[name2])\n",
    "        pct = 100 * overlap / PATCH_SIZE\n",
    "        print(f\"{name1:<15} {name2:<15} {overlap:<10} {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nWith {PATCH_SIZE} points per patch, low overlap means different groupings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Attention Complexity Analysis\n",
    "\n",
    "**Why serialization + local attention matters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(coords)  # Total points\n",
    "K = PATCH_SIZE   # Patch size\n",
    "num_patches = (N + K - 1) // K\n",
    "\n",
    "print(\"ATTENTION COMPLEXITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNumber of points (N): {N:,}\")\n",
    "print(f\"Patch size (K): {K}\")\n",
    "print(f\"Number of patches: {num_patches}\")\n",
    "\n",
    "# Global attention\n",
    "global_ops = N * N\n",
    "print(f\"\\n1. GLOBAL ATTENTION (no serialization):\")\n",
    "print(f\"   Operations: N² = {global_ops:,}\")\n",
    "\n",
    "# Local attention with patches\n",
    "local_ops = num_patches * K * K\n",
    "print(f\"\\n2. LOCAL PATCH ATTENTION (with serialization):\")\n",
    "print(f\"   Operations: (N/K) × K² = {local_ops:,}\")\n",
    "\n",
    "# Speedup\n",
    "speedup = global_ops / local_ops\n",
    "print(f\"\\n3. SPEEDUP: {speedup:.1f}×\")\n",
    "\n",
    "# Memory savings\n",
    "print(f\"\\n4. MEMORY (attention matrix):\")\n",
    "print(f\"   Global: {N}×{N} = {N*N:,} elements\")\n",
    "print(f\"   Local:  {num_patches} × ({K}×{K}) = {num_patches * K * K:,} elements\")\n",
    "print(f\"   Memory reduction: {N*N / (num_patches * K * K):.1f}×\")\n",
    "\n",
    "# PTv3 scale\n",
    "print(f\"\\n5. AT PTv3 SCALE (K=1024, N=100,000):\")\n",
    "N_ptv3 = 100000\n",
    "K_ptv3 = 1024\n",
    "global_ptv3 = N_ptv3 * N_ptv3\n",
    "local_ptv3 = (N_ptv3 // K_ptv3) * K_ptv3 * K_ptv3\n",
    "print(f\"   Global: {global_ptv3:,} operations\")\n",
    "print(f\"   Local:  {local_ptv3:,} operations\")\n",
    "print(f\"   Speedup: {global_ptv3/local_ptv3:.0f}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Complete Serialization Pipeline (PTv3 Style)\n",
    "\n",
    "Let's put it all together in a single class, similar to how PTv3 implements it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudSerializer:\n",
    "    \"\"\"\n",
    "    Complete serialization pipeline for point cloud transformers.\n",
    "    \n",
    "    This mimics the serialization in PTv3/LitePT.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        grid_size: float = 0.05,\n",
    "        patch_size: int = 64,\n",
    "        orders: tuple = ('z', 'z-trans', 'hilbert', 'hilbert-trans'),\n",
    "        depth: int = 16\n",
    "    ):\n",
    "        self.grid_size = grid_size\n",
    "        self.patch_size = patch_size\n",
    "        self.orders = orders\n",
    "        self.depth = depth\n",
    "    \n",
    "    def serialize(self, coords: np.ndarray) -> dict:\n",
    "        \"\"\"\n",
    "        Complete serialization of a point cloud.\n",
    "        \n",
    "        Args:\n",
    "            coords: (N, 3) array of [x, y, z] coordinates\n",
    "        \n",
    "        Returns:\n",
    "            dict with:\n",
    "            - grid_coords: quantized coordinates\n",
    "            - serialized_codes: list of codes for each pattern\n",
    "            - serialized_order: list of sort indices for each pattern\n",
    "            - serialized_inverse: list of inverse indices\n",
    "            - n_points: number of points\n",
    "            - n_patches: number of patches\n",
    "        \"\"\"\n",
    "        # Step 1: Normalize and quantize\n",
    "        coords_norm = coords - coords.min(axis=0)\n",
    "        grid_coords = np.floor(coords_norm / self.grid_size).astype(np.int64)\n",
    "        \n",
    "        # Step 2: Compute all serialization patterns\n",
    "        result = {\n",
    "            'coords': coords_norm,\n",
    "            'grid_coords': grid_coords,\n",
    "            'serialized_codes': [],\n",
    "            'serialized_order': [],\n",
    "            'serialized_inverse': [],\n",
    "            'n_points': len(coords),\n",
    "            'n_patches': (len(coords) + self.patch_size - 1) // self.patch_size\n",
    "        }\n",
    "        \n",
    "        for order in self.orders:\n",
    "            codes = self._encode(grid_coords, order)\n",
    "            sorted_idx = np.argsort(codes)\n",
    "            inverse_idx = np.argsort(sorted_idx)\n",
    "            \n",
    "            result['serialized_codes'].append(codes)\n",
    "            result['serialized_order'].append(sorted_idx)\n",
    "            result['serialized_inverse'].append(inverse_idx)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _encode(self, grid_coords: np.ndarray, order: str) -> np.ndarray:\n",
    "        \"\"\"Encode grid coordinates based on the specified order.\"\"\"\n",
    "        if order == 'z':\n",
    "            return z_order_encode(grid_coords, self.depth)\n",
    "        elif order == 'z-trans':\n",
    "            return z_order_encode_trans(grid_coords, self.depth)\n",
    "        elif order == 'hilbert':\n",
    "            return hilbert_encode_simple(grid_coords, self.depth)\n",
    "        elif order == 'hilbert-trans':\n",
    "            transposed = grid_coords[:, [1, 0, 2]]\n",
    "            return hilbert_encode_simple(transposed, self.depth)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown order: {order}\")\n",
    "    \n",
    "    def get_patches(self, result: dict, layer_idx: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get patch indices for a specific layer.\n",
    "        \n",
    "        Layer index determines which serialization pattern to use.\n",
    "        \"\"\"\n",
    "        order_idx = layer_idx % len(self.orders)\n",
    "        sorted_idx = result['serialized_order'][order_idx]\n",
    "        \n",
    "        patches = []\n",
    "        n = result['n_points']\n",
    "        \n",
    "        for i in range(0, n, self.patch_size):\n",
    "            end_idx = min(i + self.patch_size, n)\n",
    "            patch = sorted_idx[i:end_idx]\n",
    "            \n",
    "            # Pad if necessary\n",
    "            if len(patch) < self.patch_size and i > 0:\n",
    "                pad_size = self.patch_size - len(patch)\n",
    "                padding = sorted_idx[i - pad_size:i]\n",
    "                patch = np.concatenate([patch, padding])\n",
    "            \n",
    "            patches.append(patch)\n",
    "        \n",
    "        return patches, sorted_idx\n",
    "\n",
    "# Test the complete pipeline\n",
    "print(\"Testing complete serialization pipeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "serializer = PointCloudSerializer(\n",
    "    grid_size=0.05,\n",
    "    patch_size=64,\n",
    "    orders=('z', 'z-trans', 'hilbert', 'hilbert-trans')\n",
    ")\n",
    "\n",
    "# Run serialization\n",
    "serial_result = serializer.serialize(coords_raw)\n",
    "\n",
    "print(f\"\\nSerialization complete!\")\n",
    "print(f\"  Points: {serial_result['n_points']}\")\n",
    "print(f\"  Patches: {serial_result['n_patches']}\")\n",
    "print(f\"  Patterns: {serializer.orders}\")\n",
    "\n",
    "# Test getting patches for different layers\n",
    "print(f\"\\nPatches for each layer (showing first patch):\")\n",
    "for layer in range(4):\n",
    "    patches, _ = serializer.get_patches(serial_result, layer)\n",
    "    pattern = serializer.orders[layer % len(serializer.orders)]\n",
    "    print(f\"  Layer {layer} ({pattern}): Patch 0 indices = {patches[0][:5].tolist()}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **Grid Quantization**: Continuous coords → Discrete grid coords\n",
    "   - `(0.15, 0.27, 0.43) → (3, 5, 8)` with grid_size=0.05\n",
    "\n",
    "2. **Z-Order Encoding**: Grid coords → Morton code (bit interleaving)\n",
    "   - `(3, 5, 8) → interleave bits → single integer`\n",
    "\n",
    "3. **Sorting**: Create ordered sequence by Morton codes\n",
    "   - Spatially nearby points get nearby positions\n",
    "\n",
    "4. **Patch Grouping**: Split into fixed-size groups\n",
    "   - Enables local attention: O(NK) instead of O(N²)\n",
    "\n",
    "5. **Shuffle Order**: Cycle through 4 patterns\n",
    "   - Different patterns → Different groupings\n",
    "   - Ensures all points eventually interact\n",
    "\n",
    "### LitePT's insight:\n",
    "- Only use serialization + attention at **late stages** (E3, E4)\n",
    "- Use convolution at **early stages** (E0, E1, E2)\n",
    "- Replace heavy conv-based positional encoding with **PointROPE** (parameter-free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization: Summary of the complete pipeline\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Original point cloud\n",
    "ax1 = fig.add_subplot(231, projection='3d')\n",
    "ax1.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "           c=df['intensity'].values, cmap='viridis', s=1)\n",
    "ax1.set_title('1. Original Point Cloud')\n",
    "ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')\n",
    "\n",
    "# 2. Grid visualization\n",
    "ax2 = fig.add_subplot(232, projection='3d')\n",
    "ax2.scatter(grid_coords[:, 0], grid_coords[:, 1], grid_coords[:, 2], \n",
    "           c=morton_codes, cmap='viridis', s=1)\n",
    "ax2.set_title('2. Grid Coordinates\\n(colored by Morton code)')\n",
    "ax2.set_xlabel('Grid X'); ax2.set_ylabel('Grid Y'); ax2.set_zlabel('Grid Z')\n",
    "\n",
    "# 3. Serialization order\n",
    "ax3 = fig.add_subplot(233, projection='3d')\n",
    "ax3.scatter(coords[:, 0], coords[:, 1], coords[:, 2], \n",
    "           c=serial_position, cmap='plasma', s=1)\n",
    "ax3.set_title('3. Serialization Order\\n(colored by position)')\n",
    "ax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')\n",
    "\n",
    "# 4. Patch grouping\n",
    "ax4 = fig.add_subplot(234, projection='3d')\n",
    "for i, patch in enumerate(patches[:15]):\n",
    "    patch_coords = coords[patch]\n",
    "    ax4.scatter(patch_coords[:, 0], patch_coords[:, 1], patch_coords[:, 2],\n",
    "               c=[colors[i % 20]], s=2, alpha=0.7)\n",
    "ax4.set_title('4. Patch Grouping\\n(first 15 patches)')\n",
    "ax4.set_xlabel('X'); ax4.set_ylabel('Y'); ax4.set_zlabel('Z')\n",
    "\n",
    "# 5. Shuffle order comparison\n",
    "ax5 = fig.add_subplot(235, projection='3d')\n",
    "for idx, (name, sorted_idx) in enumerate(all_patterns.items()):\n",
    "    patch_0 = sorted_idx[:PATCH_SIZE]\n",
    "    patch_coords = coords[patch_0]\n",
    "    ax5.scatter(patch_coords[:, 0], patch_coords[:, 1], patch_coords[:, 2],\n",
    "               c=colors_patch[idx], s=5, alpha=0.5, label=name)\n",
    "ax5.set_title('5. Shuffle Order\\n(Patch 0 in each pattern)')\n",
    "ax5.set_xlabel('X'); ax5.set_ylabel('Y'); ax5.set_zlabel('Z')\n",
    "ax5.legend(fontsize=8)\n",
    "\n",
    "# 6. Complexity comparison (text)\n",
    "ax6 = fig.add_subplot(236)\n",
    "ax6.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "SERIALIZATION SUMMARY\n",
    "{'='*30}\n",
    "\n",
    "Points: {N:,}\n",
    "Grid size: {GRID_SIZE}m\n",
    "Patch size: {PATCH_SIZE}\n",
    "Patches: {num_patches}\n",
    "\n",
    "COMPLEXITY:\n",
    "  Global attention: {N*N:,} ops\n",
    "  Local attention:  {num_patches*PATCH_SIZE*PATCH_SIZE:,} ops\n",
    "  Speedup: {N*N/(num_patches*PATCH_SIZE*PATCH_SIZE):.1f}×\n",
    "\n",
    "PATTERNS:\n",
    "  • z-order\n",
    "  • z-order-trans (swap x,y)\n",
    "  • hilbert\n",
    "  • hilbert-trans\n",
    "\"\"\"\n",
    "ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, \n",
    "        fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Point Cloud Serialization Pipeline (PTv3/LitePT)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
